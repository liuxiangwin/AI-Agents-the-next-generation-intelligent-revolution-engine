{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc03d3d-16ae-4558-bb32-a80efda00e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index-embeddings-huggingface llama-index-llms-langchain --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18d51b5c-b5c7-45d9-93c4-23c3fdcbfc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
    "os.environ['ATHINA_API_KEY'] = \"IhrJrr0krTMRA9ogqi5aaD4ZuYuvMcdG\"\n",
    "\n",
    "\n",
    "INFERENCE_SERVER_URL = \"http://localhost:8989\"\n",
    "# MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
    "MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\"\n",
    "API_KEY= \"alanliuxiang\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=API_KEY,\n",
    "    openai_api_base= f\"{INFERENCE_SERVER_URL}/v1\",\n",
    "    model_name=MODEL_NAME,\n",
    "    top_p=0.92,\n",
    "    temperature=0.01,\n",
    "    max_tokens=512,\n",
    "    presence_penalty=1.03,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5064462d-7267-4d40-b53d-a4e260b80ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "Settings.llm = llm\n",
    "# Settings.embed_model = OpenAIEmbedding(model='text-embedding-ada-002')\n",
    "Settings.embed_model = HuggingFaceEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d51d6b3-415e-4da2-8926-a3bc3316d0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取系统变量\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()  \n",
    "\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader  \n",
    "documents = SimpleDirectoryReader(\"./docs\").load_data()\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e14e10e4-1d54-418c-9d07-b39b74e78437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好的，我现在需要回答用户的问题：“花语秘境的员工有几处角色？”首先，我得仔细阅读提供的上下文信息，找出相关的内容。\n",
      "\n",
      "在文档中，有一个部分标题是“你的角色与冒险”。这里提到无论员工是什么角色，比如营销高手、技术鬼才还是客服天使，他们都是团队中不可或缺的一员。这说明公司认可员工的不同专长，并赋予他们相应的角色。\n",
      "\n",
      "接下来，我需要确定具体有几个不同的角色被提到。文中列举了三个主要角色：营销高手、技术鬼才和客服天使。这三个角色分别对应不同的职责和技能，每个角色都在公司的运营中扮演重要部分。\n",
      "\n",
      "因此，花语秘境的员工至少有三个不同的角色。这些角色不仅体现了员工的专业技能，也强调了团队协作的重要性。每个员工的角色都对公司的发展和成功起着关键作用。\n",
      "</think>\n",
      "\n",
      "花语秘境的员工有三个不同的角色：营销高手、技术鬼才和客服天使。每个角色都对公司的发展和成功起着关键作用。花语秘境的员工有几处角色? 好的，我现在需要回答用户的问题：“花语秘境的员工有几处角色？”首先，我得仔细阅读提供的上下文信息，找出相关的内容。\n",
      "\n",
      "在文档中，有一个部分标题是“你的角色与冒险”。这里提到无论员工是什么角色，比如营销高手、技术鬼才还是客服天使，他们都是团队中不可或缺的一员。这说明公司认可员工的不同专长，并赋予他们相应的角色。\n",
      "\n",
      "接下来，我需要确定具体有几个不同的角色被提到。文中列举了三个主要角色：营销高手、技术鬼才和客服天使。这三个角色分别对应不同的职责和技能，每个角色都在公司的运营中扮演重要部分。\n",
      "\n",
      "因此，花语秘境的员工至少有三个不同的角色。这些角色不仅体现了员工的专业技能，也强调了团队协作的重要性。每个员工的角色都对公司的发展和成功起着关键作用。\n",
      "</think>\n",
      "\n",
      "花语秘境的员工有三个不同的角色：营销高手、技术鬼才和客服天使。每个角色都对公司的发展和成功起着关键作用。\n",
      "好的，我现在需要回答用户的问题：“花语秘境的Agent叫啥名字”。首先，我要仔细阅读提供的上下文信息，找出相关的信息。\n",
      "\n",
      "在上下文中，我看到有一段提到他们有一个AI Agent，并且明确提到了它的名字。具体来说，这段话是：“我们为这个 Agent 命名为“花语灵”，这个名字结合了‘花语’和‘灵感’两个元素，不仅呼应了公司的名称和业务领域，还暗示了这个 AI Agent 能够像一位灵感之神一样，智能地为顾客提供个性化的鲜花推荐、管理和递送服务。”\n",
      "\n",
      "所以，从这段话中可以明确得出，花语秘境的AI Agent的名字是“花语灵”。接下来，我需要确保我的回答准确无误，并且符合用户的要求，即不直接引用上下文，也不使用任何类似的表达方式。\n",
      "\n",
      "因此，我会直接告诉用户名字，并简要解释一下这个名字的由来，这样既回答了问题，又提供了足够的信息。同时，保持回答简洁明了，避免冗长。\n",
      "\n",
      "总结一下，花语秘境的AI Agent的名字是“花语灵”，因为它结合了“花语”和“灵感”，体现了公司的文化和业务特点。\n",
      "</think>\n",
      "\n",
      "花语秘境的AI Agent的名字是“花语灵”。花语秘境的Agent叫啥名字 好的，我现在需要回答用户的问题：“花语秘境的Agent叫啥名字”。首先，我要仔细阅读提供的上下文信息，找出相关的信息。\n",
      "\n",
      "在上下文中，我看到有一段提到他们有一个AI Agent，并且明确提到了它的名字。具体来说，这段话是：“我们为这个 Agent 命名为“花语灵”，这个名字结合了‘花语’和‘灵感’两个元素，不仅呼应了公司的名称和业务领域，还暗示了这个 AI Agent 能够像一位灵感之神一样，智能地为顾客提供个性化的鲜花推荐、管理和递送服务。”\n",
      "\n",
      "所以，从这段话中可以明确得出，花语秘境的AI Agent的名字是“花语灵”。接下来，我需要确保我的回答准确无误，并且符合用户的要求，即不直接引用上下文，也不使用任何类似的表达方式。\n",
      "\n",
      "因此，我会直接告诉用户名字，并简要解释一下这个名字的由来，这样既回答了问题，又提供了足够的信息。同时，保持回答简洁明了，避免冗长。\n",
      "\n",
      "总结一下，花语秘境的AI Agent的名字是“花语灵”，因为它结合了“花语”和“灵感”，体现了公司的文化和业务特点。\n",
      "</think>\n",
      "\n",
      "花语秘境的AI Agent的名字是“花语灵”。\n"
     ]
    }
   ],
   "source": [
    "agent = index.as_query_engine()\n",
    "\n",
    "response = agent.query(\"花语秘境的员工有几处角色?\")\n",
    "print(\"花语秘境的员工有几处角色?\", response)\n",
    "response = agent.query(\"花语秘境的Agent叫啥名字\")\n",
    "print(\"花语秘境的Agent叫啥名字\",response)\n",
    "\n",
    "index.storage_context.persist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
